# Asymptotic Notations


### Asymptotic Analysis

1. In this tutorial, you will learn what asymptotic notations.
2. Also, you will about Big-O notation,Theta notation,Omega notation.
3. The efficiency of an algorithm depends on the amount of time, storage and other resources required to execute the algorithm.
4. The efficiency is measured with the help of asymptotic notations.
5. An algorithm may not have the same performance for different types of input.
6. With the increase in input size, the performance with change.
7. The study of change in performance of the algorithm with the change in the order of the input size is defined as asymptotic analysis.

### Asymptotic Notatiions

1. Asymptotic notations are the mathematical notations used to describe the running time of an algorithm when the input tends towards a particular value or a limiting value.
2. For exampleL: In bubble sort, when the input array is already sorted, the time taken by the algorithm is linear i.e, the best case.
3. But, When the input array is in reverse condition, th algorithm takes the maximum time (quadratic) to sort the elements i.e. th worst case.
4. When the input array is neither sorted nor in reverse order, then it takes average time.
5. These durations are denoted using asymptotic notations.
6. There are mainly three asymptotic notations: Theta notations,Omega notations and Big-O notations.

### Theta Notation ( ùùù notation )

1. Theta notation encloses the function from above and below.
2. Since it represents the upper and the lower bound of the running time of an algorithm, it is used for analyzing the average case complexity of an algorithm.
3. For a function **g(n), ùùù (g(n))** is given by the relation:

**‚à¥ Theta bounds the function within constants factors.**

```
 ùùù (g(n)) = { f(n) : there exist positive constants c‚ÇÅ, c‚ÇÇ and n‚ÇÄ
              such that 0 ‚â§  c‚ÇÅg(n) ‚â§ f(n) ‚â§ c‚ÇÇg(n) for all n ‚â• n‚ÇÄ}
```

4. The above expression can be described as a function **f(n)** belongs to the set **ùùù(g(n))** if there exist positive constants **c‚ÇÅ** and **c‚ÇÇ** such that it can be sandwiched between **c‚ÇÅg(n)** and **c‚ÇÇg(n)**,for sufficiently large n.
5. If a function **f(n)** lies anywhere in between **c‚ÇÅg(n)** and **c‚ÇÇ > g(n)** for all **n ‚â• n‚ÇÄ**, then **f(n)** is said to be asymptotically tight bound.  

### Big-O Notation (O notation)

1. Big-O notation represents the upper bound of the running time of an algorithm.
2. Thus, it gives the worst case complexity of an algorithm.

**‚à¥ Big-O gives the upper bound of a function.**

```
O(g(n)) = { f(n): there exist positive constants c and n‚ÇÄ
            such that 0 ‚â§ f(n) ‚â§ cg(n) for all n ‚â• n‚ÇÄ }
```

3. The above expression can be described as a function **f(n)** belongs to the set **O(g(n))** if there exists a positive constant **c** such that it lies between **0** and **cg(n)**, for sufficiently large **n**.
4. For any value of **n**, the running time of an algorithm does not cross time provided by **O(g(n))**;
5. Since it gives the worst case running time of an algorithm, it is widely used to analyze an algorithm as we are always interested in the worst case scenario.
 
### Omega Notation (ùõÄ - notation)

1. Omega notation represents the lower bound of the running time of an algorithm.
2. Thus, it provides best case complexity of an algorithm.

**‚à¥ Omega gives the lower bound of a function.**

```
ùõÄ(g(n)) = { f(n): there exist positive constants c and n‚ÇÄ
            such that 0 ‚â§ cg(n) ‚â§ f(n) for all n ‚â• n‚ÇÄ  }

```

3. The above expression can be descried as a function **f(n)** belongs to the set **ùõÄ(g(n))** if there exists a positive constant **c** such that it lies above **cg(n)**, for sufficiently large **n**.
4. For any value of **n**, the minimum time required by the algorithm is given by Omega **ùõÄ(g(n))**.
